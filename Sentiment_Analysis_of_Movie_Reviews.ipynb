{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhhiixxhek/Sentiment-Analysis-of-Movie-Reviews/blob/main/Sentiment_Analysis_of_Movie_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ToIExVBqiIsn"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oTE-5EKhsJjz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd    # to load dataset\n",
        "import numpy as np     # for mathematic equation\n",
        "\n",
        "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
        "from tensorflow.keras.models import Sequential     # the model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
        "from tensorflow.keras.models import load_model   # load saved model\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1gqW1VWS127M",
        "outputId": "bdb4d86c-7a16-4722-b599-749d8f0a3bd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2432e535-42e9-4515-bcdd-24b943e54a75\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2432e535-42e9-4515-bcdd-24b943e54a75')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2432e535-42e9-4515-bcdd-24b943e54a75 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2432e535-42e9-4515-bcdd-24b943e54a75');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ae7d3c82-bed3-49a6-83bc-1f2a59c0f912\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae7d3c82-bed3-49a6-83bc-1f2a59c0f912')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ae7d3c82-bed3-49a6-83bc-1f2a59c0f912 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49582,\n        \"samples\": [\n          \"\\\"Soul Plane\\\" is a horrible attempt at comedy that only should appeal people with thick skulls, bloodshot eyes and furry pawns. <br /><br />The plot is not only incoherent but also non-existent, acting is mostly sub sub-par with a gang of highly moronic and dreadful characters thrown in for bad measure, jokes are often spotted miles ahead and almost never even a bit amusing. This movie lacks any structure and is full of racial stereotypes that must have seemed old even in the fifties, the only thing it really has going for it is some pretty ladies, but really, if you want that you can rent something from the \\\"Adult\\\" section. OK?<br /><br />I can hardly see anything here to recommend since you'll probably have a lot a better and productive time chasing rats with a sledgehammer or inventing waterproof teabags or whatever.<br /><br />2/10\",\n          \"Guest from the Future tells a fascinating story of time travel, friendship, battle of good and evil -- all with a small budget, child actors, and few special effects. Something for Spielberg and Lucas to learn from. ;) A sixth-grader Kolya \\\"Nick\\\" Gerasimov finds a time machine in the basement of a decrepit building and travels 100 years into the future. He discovers a near-perfect, utopian society where robots play guitars and write poetry, everyone is kind to each other and people enjoy everything technology has to offer. Alice is the daughter of a prominent scientist who invented a device called Mielophone that allows to read minds of humans and animals. The device can be put to both good and bad use, depending on whose hands it falls into. When two evil space pirates from Saturn who want to rule the universe attempt to steal Mielophone, it falls into the hands of 20th century school boy Nick. With the pirates hot on his tracks, he travels back to his time, followed by the pirates, and Alice. Chaos, confusion and funny situations follow as the luckless pirates try to blend in with the earthlings. Alice enrolls in the same school Nick goes to and demonstrates superhuman abilities in PE class. The catch is, Alice doesn't know what Nick looks like, while the pirates do. Also, the pirates are able to change their appearance and turn literally into anyone. (Hmm, I wonder if this is where James Cameron got the idea for Terminator...) Who gets to Nick -- and Mielophone -- first? Excellent plot, non-stop adventures, and great soundtrack. I wish Hollywood made kid movies like this one...\",\n          \"\\\"National Treasure\\\" (2004) is a thoroughly misguided hodge-podge of plot entanglements that borrow from nearly every cloak and dagger government conspiracy clich\\u00e9 that has ever been written. The film stars Nicholas Cage as Benjamin Franklin Gates (how precious is that, I ask you?); a seemingly normal fellow who, for no other reason than being of a lineage of like-minded misguided fortune hunters, decides to steal a 'national treasure' that has been hidden by the United States founding fathers. After a bit of subtext and background that plays laughably (unintentionally) like Indiana Jones meets The Patriot, the film degenerates into one misguided whimsy after another \\u0096 attempting to create a 'Stanley Goodspeed' regurgitation of Nicholas Cage and launch the whole convoluted mess forward with a series of high octane, but disconnected misadventures.<br /><br />The relevancy and logic to having George Washington and his motley crew of patriots burying a king's ransom someplace on native soil, and then, going through the meticulous plan of leaving clues scattered throughout U.S. currency art work, is something that director Jon Turteltaub never quite gets around to explaining. Couldn't Washington found better usage for such wealth during the start up of the country? Hence, we are left with a mystery built on top of an enigma that is already on shaky ground by the time Ben appoints himself the new custodian of this untold wealth. Ben's intentions are noble \\u0096 if confusing. He's set on protecting the treasure. For who and when?\\u0085your guess is as good as mine.<br /><br />But there are a few problems with Ben's crusade. First up, his friend, Ian Holmes (Sean Bean) decides that he can't wait for Ben to make up his mind about stealing the Declaration of Independence from the National Archives (oh, yeah \\u0096 brilliant idea!). Presumably, the back of that famous document holds the secret answer to the ultimate fortune. So Ian tries to kill Ben. The assassination attempt is, of course, unsuccessful, if overly melodramatic. It also affords Ben the opportunity to pick up, and pick on, the very sultry curator of the archives, Abigail Chase (Diane Kruger). She thinks Ben is clearly a nut \\u0096 at least at the beginning. But true to action/romance form, Abby's resolve melts quicker than you can say, \\\"is that the Hope Diamond?\\\" The film moves into full X-File-ish mode, as the FBI, mistakenly believing that Ben is behind the theft, retaliate in various benign ways that lead to a multi-layering of action sequences reminiscent of Mission Impossible meets The Fugitive. Honestly, don't those guys ever get 'intelligence' information that is correct? In the final analysis, \\\"National Treasure\\\" isn't great film making, so much as it's a patchwork rehash of tired old bits from other movies, woven together from scraps, the likes of which would make IL' Betsy Ross blush.<br /><br />The Buena Vista DVD delivers a far more generous treatment than this film is deserving of. The anamorphic widescreen picture exhibits a very smooth and finely detailed image with very rich colors, natural flesh tones, solid blacks and clean whites. The stylized image is also free of blemishes and digital enhancements. The audio is 5.1 and delivers a nice sonic boom to your side and rear speakers with intensity and realism. Extras include a host of promotional junket material that is rather deep and over the top in its explanation of how and why this film was made. If only, as an audience, we had had more clarification as to why Ben and co. were chasing after an illusive treasure, this might have been one good flick. Extras conclude with the theatrical trailer, audio commentary and deleted scenes. Not for the faint-hearted \\u0096 just the thick-headed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data = pd.read_csv(r\"/content/IMDB_Dataset.csv\")\n",
        "\n",
        "\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FSBIDzeVw8q-"
      },
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# d1 = data\n",
        "# le = LabelEncoder()\n",
        "# d1['sentiment'] = le.fit_transform(d1['sentiment'])\n",
        "\n",
        "# X = d1.drop('sentiment', axis=1)\n",
        "# y = d1['sentiment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNNH6bxLzwSB",
        "outputId": "ed643b7a-94d5-45c3-bf89-a84b4fe1c10f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews\n",
            "0        [one, reviewers, mentioned, watching, oz, epis...\n",
            "1        [a, wonderful, little, production, the, filmin...\n",
            "2        [i, thought, wonderful, way, spend, time, hot,...\n",
            "3        [basically, family, little, boy, jake, thinks,...\n",
            "4        [petter, mattei, love, time, money, visually, ...\n",
            "                               ...                        \n",
            "49995    [i, thought, movie, right, good, job, it, crea...\n",
            "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
            "49997    [i, catholic, taught, parochial, elementary, s...\n",
            "49998    [i, going, disagree, previous, comment, side, ...\n",
            "49999    [no, one, expects, star, trek, movies, high, a...\n",
            "Name: review, Length: 50000, dtype: object \n",
            "\n",
            "Sentiment\n",
            "0        1\n",
            "1        1\n",
            "2        1\n",
            "3        0\n",
            "4        1\n",
            "        ..\n",
            "49995    1\n",
            "49996    0\n",
            "49997    0\n",
            "49998    0\n",
            "49999    0\n",
            "Name: sentiment, Length: 50000, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "english_stops = set(nltk.corpus.stopwords.words('english'))\n",
        "def load_dataset():\n",
        "    df = pd.read_csv('IMDB_Dataset.csv')\n",
        "    x_data = df['review']       # Reviews/Input\n",
        "    y_data = df['sentiment']    # Sentiment/Output\n",
        "\n",
        "    # PRE-PROCESS REVIEW\n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\n",
        "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\n",
        "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\n",
        "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\n",
        "\n",
        "    # ENCODE SENTIMENT -> 0 & 1\n",
        "    y_data = y_data.replace('positive', 1)\n",
        "    y_data = y_data.replace('negative', 0)\n",
        "\n",
        "    return x_data, y_data\n",
        "\n",
        "x_data, y_data = load_dataset()\n",
        "\n",
        "print('Reviews')\n",
        "print(x_data, '\\n')\n",
        "print('Sentiment')\n",
        "print(y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkfhXIU20Iv0"
      },
      "source": [
        "## Spit Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtpWP2WG0NhY",
        "outputId": "34d74b96-e154-4a40-8009-67499779462d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set\n",
            "17792    [first, i, like, make, correction, another, re...\n",
            "23307    [this, four, hour, miniseries, production, two...\n",
            "34651    [the, directing, behind, film, fantastic, come...\n",
            "30160    [i, really, disappointed, film, the, first, wa...\n",
            "3199     [dramatic, license, hate, though, necessary, r...\n",
            "                               ...                        \n",
            "43326    [there, movies, films, movies, often, merely, ...\n",
            "48547    [arthur, miller, always, known, one, america, ...\n",
            "27690    [the, main, reason, watching, picture, savor, ...\n",
            "10186    [but, even, caricatures, need, plausible, plot...\n",
            "26764    [legendary, movie, producer, walt, disney, bro...\n",
            "Name: review, Length: 40000, dtype: object \n",
            "\n",
            "6206     [one, favorite, movies, ever, along, casablanc...\n",
            "43186    [this, must, see, anybody, loves, thriller, sp...\n",
            "18210    [i, love, horror, films, i, think, work, way, ...\n",
            "7276     [this, movie, worse, heaven, gate, plan, outer...\n",
            "19748    [this, probably, greatest, war, film, certainl...\n",
            "                               ...                        \n",
            "8907     [this, film, antonioni, middle, period, critic...\n",
            "42830    [terry, benedict, andy, garcia, catches, danny...\n",
            "39721    [best, showing, think, jesus, really, like, mo...\n",
            "43870    [dev, anand, prashant, zeenat, aman, jasbir, j...\n",
            "519      [i, type, guy, loves, hood, movies, new, jack,...\n",
            "Name: review, Length: 10000, dtype: object \n",
            "\n",
            "Test Set\n",
            "17792    1\n",
            "23307    0\n",
            "34651    1\n",
            "30160    0\n",
            "3199     1\n",
            "        ..\n",
            "43326    1\n",
            "48547    0\n",
            "27690    1\n",
            "10186    0\n",
            "26764    1\n",
            "Name: sentiment, Length: 40000, dtype: int64 \n",
            "\n",
            "6206     1\n",
            "43186    1\n",
            "18210    1\n",
            "7276     0\n",
            "19748    1\n",
            "        ..\n",
            "8907     1\n",
            "42830    0\n",
            "39721    1\n",
            "43870    1\n",
            "519      0\n",
            "Name: sentiment, Length: 10000, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\n",
        "\n",
        "print('Train Set')\n",
        "print(x_train, '\\n')\n",
        "print(x_test, '\\n')\n",
        "print('Test Set')\n",
        "print(y_train, '\\n')\n",
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pfTsKDMr0Umi"
      },
      "outputs": [],
      "source": [
        "def get_max_length():\n",
        "    review_length = []\n",
        "    for review in x_train:\n",
        "        review_length.append(len(review))\n",
        "\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W56Fu6g0Z1s"
      },
      "source": [
        "## Tokenize and Pad/Truncate Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCUku9kr0dDz",
        "outputId": "069b502a-3bfb-44f3-97f1-58a5207365d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17792    [first, i, like, make, correction, another, re...\n",
            "23307    [this, four, hour, miniseries, production, two...\n",
            "34651    [the, directing, behind, film, fantastic, come...\n",
            "30160    [i, really, disappointed, film, the, first, wa...\n",
            "3199     [dramatic, license, hate, though, necessary, r...\n",
            "                               ...                        \n",
            "43326    [there, movies, films, movies, often, merely, ...\n",
            "48547    [arthur, miller, always, known, one, america, ...\n",
            "27690    [the, main, reason, watching, picture, savor, ...\n",
            "10186    [but, even, caricatures, need, plausible, plot...\n",
            "26764    [legendary, movie, producer, walt, disney, bro...\n",
            "Name: review, Length: 40000, dtype: object\n",
            "Encoded X Train\n",
            " [[   23     1     6 ...   257  1439 57000]\n",
            " [    9   569   421 ...   721     4  3721]\n",
            " [    2   891   423 ...     0     0     0]\n",
            " ...\n",
            " [    2   188   195 ... 12114 13439  4171]\n",
            " [   29    11  5905 ...     0     0     0]\n",
            " [ 2606     3  1184 ...   494  1593 16873]] \n",
            "\n",
            "Encoded X Test\n",
            " [[    5   416    28 ...     0     0     0]\n",
            " [    9   113    15 ...     0     0     0]\n",
            " [    1    40    92 ...     0     0     0]\n",
            " ...\n",
            " [   46   652    31 ...     0     0     0]\n",
            " [ 8288  9461 19992 ...     0     0     0]\n",
            " [    1   450   115 ...    33  3987   509]] \n",
            "\n",
            "Maximum review length:  130\n"
          ]
        }
      ],
      "source": [
        "print(x_train)\n",
        "# ENCODE REVIEW\n",
        "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "\n",
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-eLwcuF0qg4"
      },
      "source": [
        "# Build Architecture/Model\n",
        "\n",
        "**Embedding Layer:** in simple terms, it creates word vectors of each word in the word_index and group words that are related or have similar meaning by analyzing other words around them.\n",
        "\n",
        "**LSTM Layer:** to make a decision to keep or throw away data by considering the current input, previous output, and previous memory. There are some important components in LSTM.\n",
        "\n",
        "- **Forget Gate**, decides information is to be kept or thrown away\n",
        "- Input Gate, updates cell state by passing previous output and current input into sigmoid activation function\n",
        "- **Cell State**, calculate new cell state, it is multiplied by forget vector (drop value if multiplied by a near 0), add it with the output from input gate to update the cell state value.\n",
        "- **Ouput Gate**, decides the next hidden state and used for predictions\n",
        "\n",
        "**Dense Layer:** compute the input with the weight matrix and bias (optional), and using an activation function. I use Sigmoid activation function for this work because the output is only 0 or 1.\n",
        "\n",
        "The optimizer is Adam and the loss function is Binary Crossentropy because again the output is only 0 and 1, which is a binary number."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sIaM2EhIbID"
      },
      "source": [
        "## Model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qlwsJr20rUq",
        "outputId": "1b74061a-02ec-44b5-a7de-c2726563497a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 130, 32)           2955360   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                24832     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 964)               62660     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 965       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3043817 (11.61 MB)\n",
            "Trainable params: 3043817 (11.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "# ARCHITECTURE\n",
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
        "model.add(LSTM(LSTM_OUT))\n",
        "model.add(Dense(964, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "plot_model(model, to_file='model1LSTM.png')\n",
        "print(model.summary())\n",
        "checkpoint1 = ModelCheckpoint(\n",
        "    'LSTM1_2.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqUDCs4S0yc3",
        "outputId": "64d4d5bd-d44c-4b47-b6df-fb1d802b4305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.4525 - accuracy: 0.7477\n",
            "Epoch 1: accuracy improved from -inf to 0.74775, saving model to LSTM1_2.h5\n",
            "313/313 [==============================] - 48s 138ms/step - loss: 0.4525 - accuracy: 0.7477\n",
            "Epoch 2/5\n",
            "  1/313 [..............................] - ETA: 4s - loss: 0.1846 - accuracy: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - ETA: 0s - loss: 0.1976 - accuracy: 0.9274\n",
            "Epoch 2: accuracy improved from 0.74775 to 0.92738, saving model to LSTM1_2.h5\n",
            "313/313 [==============================] - 25s 82ms/step - loss: 0.1976 - accuracy: 0.9274\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9647\n",
            "Epoch 3: accuracy improved from 0.92738 to 0.96475, saving model to LSTM1_2.h5\n",
            "313/313 [==============================] - 19s 62ms/step - loss: 0.1079 - accuracy: 0.9647\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9804\n",
            "Epoch 4: accuracy improved from 0.96475 to 0.98037, saving model to LSTM1_2.h5\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.0656 - accuracy: 0.9804\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9874\n",
            "Epoch 5: accuracy improved from 0.98037 to 0.98740, saving model to LSTM1_2.h5\n",
            "313/313 [==============================] - 11s 34ms/step - loss: 0.0413 - accuracy: 0.9874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78e26abd1ba0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNQKYQxK06Gz",
        "outputId": "69d48563-a682-4a97-e36a-0875af0f38e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 5ms/step\n",
            "Correct Prediction: 8697\n",
            "Wrong Prediction: 1303\n",
            "Accuracy: 86.97\n"
          ]
        }
      ],
      "source": [
        "y_pred = (model.predict(x_test, batch_size = 128)> 0.5).astype(\"int32\")\n",
        "\n",
        "true = 0\n",
        "for i, y in enumerate(y_test):\n",
        "    if y == y_pred[i]:\n",
        "        true += 1\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05rjOeiplXll"
      },
      "source": [
        "## Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYXeTRWxlXOo",
        "outputId": "ac2ca074-9dcc-41bf-96ef-693b51927208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 130, 32)           2955360   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                24832     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2984417 (11.38 MB)\n",
            "Trainable params: 2984417 (11.38 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "# ARCHITECTURE\n",
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
        "model2.add(LSTM(LSTM_OUT))\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "model2.add(Dense(1, activation='softmax'))\n",
        "model2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "plot_model(model2, to_file='model2LSTM.png')\n",
        "print(model2.summary())\n",
        "checkpoint2 = ModelCheckpoint(\n",
        "    'LSTM2_2.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ-RcEp6l5Xq",
        "outputId": "821aa530-bf32-4dc4-df09-5c4ad02dc3a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.4832 - accuracy: 0.4999\n",
            "Epoch 1: accuracy improved from -inf to 0.49990, saving model to LSTM2_2.h5\n",
            "313/313 [==============================] - 32s 96ms/step - loss: 0.4832 - accuracy: 0.4999\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.4999\n",
            "Epoch 2: accuracy did not improve from 0.49990\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.2102 - accuracy: 0.4999\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.4999\n",
            "Epoch 3: accuracy did not improve from 0.49990\n",
            "313/313 [==============================] - 14s 44ms/step - loss: 0.1174 - accuracy: 0.4999\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.4999\n",
            "Epoch 4: accuracy did not improve from 0.49990\n",
            "313/313 [==============================] - 10s 30ms/step - loss: 0.0756 - accuracy: 0.4999\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.4999\n",
            "Epoch 5: accuracy did not improve from 0.49990\n",
            "313/313 [==============================] - 7s 21ms/step - loss: 0.0506 - accuracy: 0.4999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78e26abebe80>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "model2.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gNCitnxyNAW",
        "outputId": "136c2b76-c7b8-41cf-9b3d-6dbf2393d79f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 4ms/step\n",
            "Correct Predictions: 5004\n",
            "Wrong Predictions: 4996\n",
            "Accuracy: 50.04%\n"
          ]
        }
      ],
      "source": [
        "y_pred = model2.predict(x_test, batch_size=128)\n",
        "y_pred_classes = (y_pred > 0.0).astype(\"int32\")\n",
        "\n",
        "correct_predictions = np.sum(y_pred_classes.flatten() == y_test)\n",
        "total_predictions = len(y_pred_classes)\n",
        "\n",
        "accuracy = correct_predictions / total_predictions * 100\n",
        "\n",
        "print('Correct Predictions: {}'.format(correct_predictions))\n",
        "print('Wrong Predictions: {}'.format(total_predictions - correct_predictions))\n",
        "print('Accuracy: {:.2f}%'.format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6lC_k9sB8j2"
      },
      "source": [
        "## Model 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc6KL7eXB8IP",
        "outputId": "6733c95a-e7d6-4b90-9f82-06e61bf6edaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 130, 32)           2955360   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 126, 64)           10304     \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 64)                0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2967810 (11.32 MB)\n",
            "Trainable params: 2967810 (11.32 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Activation\n",
        "\n",
        "EMBED_DIM = 32\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(total_words, EMBED_DIM, input_length=max_length))\n",
        "model3.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
        "model3.add(GlobalMaxPooling1D())\n",
        "model3.add(Dense(32, activation='relu'))\n",
        "model3.add(Dense(2, activation='softmax'))\n",
        "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "plot_model(model3, to_file='model3LSTM.png')\n",
        "print(model3.summary())\n",
        "checkpoint3 = ModelCheckpoint(\n",
        "    'LSTM3_2.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnlXcKQGDulP",
        "outputId": "69ca82b7-9bd6-4e61-c870-f4a45c0fac63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.4536 - accuracy: 0.7713\n",
            "Epoch 1: accuracy improved from -inf to 0.77127, saving model to LSTM3_2.h5\n",
            "313/313 [==============================] - 31s 87ms/step - loss: 0.4536 - accuracy: 0.7713\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.9182\n",
            "Epoch 2: accuracy improved from 0.77127 to 0.91815, saving model to LSTM3_2.h5\n",
            "313/313 [==============================] - 16s 51ms/step - loss: 0.2109 - accuracy: 0.9182\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9773\n",
            "Epoch 3: accuracy improved from 0.91815 to 0.97728, saving model to LSTM3_2.h5\n",
            "313/313 [==============================] - 11s 36ms/step - loss: 0.0753 - accuracy: 0.9773\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9973\n",
            "Epoch 4: accuracy improved from 0.97728 to 0.99725, saving model to LSTM3_2.h5\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 0.0169 - accuracy: 0.9973\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9998\n",
            "Epoch 5: accuracy improved from 0.99725 to 0.99977, saving model to LSTM3_2.h5\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.0030 - accuracy: 0.9998\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78e24f324ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model3.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU7KhnW6E2TW",
        "outputId": "d41345be-e236-4be2-8dec-17bcb6d558a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 2ms/step\n",
            "Correct Predictions: 8716\n",
            "Wrong Predictions: 1284\n",
            "Accuracy: 87.16000000000001\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.argmax(model3.predict(x_test, batch_size=128), axis=1)\n",
        "\n",
        "correct = np.sum(y_pred == y_test)\n",
        "total = len(y_test)\n",
        "\n",
        "print('Correct Predictions:', correct)\n",
        "print('Wrong Predictions:', total - correct)\n",
        "print('Accuracy:', correct / total * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2ad6NTWRQ00"
      },
      "source": [
        "## Model4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoLW6KaQRTHZ",
        "outputId": "2a1252e5-23ee-4cfa-b40c-d4dc273ba03c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.4327 - accuracy: 0.7839\n",
            "Epoch 1: accuracy improved from -inf to 0.78392, saving model to LSTM4_2.h5\n",
            "313/313 [==============================] - 29s 87ms/step - loss: 0.4327 - accuracy: 0.7839\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.9239\n",
            "Epoch 2: accuracy improved from 0.78392 to 0.92390, saving model to LSTM4_2.h5\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 0.1978 - accuracy: 0.9239\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9795\n",
            "Epoch 3: accuracy improved from 0.92390 to 0.97948, saving model to LSTM4_2.h5\n",
            "313/313 [==============================] - 10s 32ms/step - loss: 0.0689 - accuracy: 0.9795\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9973\n",
            "Epoch 4: accuracy improved from 0.97948 to 0.99733, saving model to LSTM4_2.h5\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.0149 - accuracy: 0.9973\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9998\n",
            "Epoch 5: accuracy improved from 0.99733 to 0.99985, saving model to LSTM4_2.h5\n",
            "313/313 [==============================] - 6s 20ms/step - loss: 0.0026 - accuracy: 0.9998\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78e24f252590>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "\n",
        "model4 = Sequential()\n",
        "model4.add(Embedding(total_words, EMBED_DIM, input_length=max_length))\n",
        "model4.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "model4.add(GlobalMaxPooling1D())\n",
        "model4.add(Dense(64, activation='relu'))\n",
        "model4.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "checkpoint4 = ModelCheckpoint(\n",
        "    'LSTM4_2.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "model4.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSZDE77_zZT7",
        "outputId": "00bda3dc-6492-47c6-cc9c-0a6e02713e23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 2ms/step\n",
            "Correct Prediction: 8714\n",
            "Wrong Prediction: 1286\n",
            "Accuracy: 87.14\n"
          ]
        }
      ],
      "source": [
        "y_pred = (model4.predict(x_test, batch_size = 128)> 0.5).astype(\"int32\")\n",
        "\n",
        "true = 0\n",
        "for i, y in enumerate(y_test):\n",
        "    if y == y_pred[i]:\n",
        "        true += 1\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0EIAjIR2xgn"
      },
      "source": [
        "## Model 5 BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hhrTT5Lb2ww7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Bidirectional, LSTM, Reshape\n",
        "\n",
        "# Define the model\n",
        "model5 = Sequential()\n",
        "model5.add(Embedding(total_words, EMBED_DIM, input_length=max_length))\n",
        "model5.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
        "model5.add(GlobalMaxPooling1D())\n",
        "model5.add(Reshape((1, 64)))  # Reshape the tensor to (batch_size, timesteps, input_dim)\n",
        "model5.add(Bidirectional(LSTM(LSTM_OUT)))\n",
        "model5.add(Dense(32, activation='relu'))\n",
        "model5.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model5.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "checkpoint5 = ModelCheckpoint(\n",
        "    'LSTM5_2.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jbLS2bR3YqF",
        "outputId": "7a7fdbfb-4dd6-436b-fd88-0eb26a91e2a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.7766\n",
            "Epoch 1: accuracy improved from -inf to 0.77660, saving model to LSTM5_2.h5\n",
            "313/313 [==============================] - 32s 87ms/step - loss: 0.4384 - accuracy: 0.7766\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9332\n",
            "Epoch 2: accuracy improved from 0.77660 to 0.93322, saving model to LSTM5_2.h5\n",
            "313/313 [==============================] - 15s 49ms/step - loss: 0.1770 - accuracy: 0.9332\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9898\n",
            "Epoch 3: accuracy improved from 0.93322 to 0.98980, saving model to LSTM5_2.h5\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.0366 - accuracy: 0.9898\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9991\n",
            "Epoch 4: accuracy improved from 0.98980 to 0.99910, saving model to LSTM5_2.h5\n",
            "313/313 [==============================] - 9s 27ms/step - loss: 0.0047 - accuracy: 0.9991\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - ETA: 0s - loss: 6.2288e-04 - accuracy: 1.0000\n",
            "Epoch 5: accuracy improved from 0.99910 to 0.99998, saving model to LSTM5_2.h5\n",
            "313/313 [==============================] - 7s 22ms/step - loss: 6.2288e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78e24f218af0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Fit the model\n",
        "model5.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "437VL5cT3bSg",
        "outputId": "ee3b080d-cdc7-4b8c-9c51-8294a6b8c532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 3ms/step\n",
            "Correct Predictions: 8741\n",
            "Wrong Predictions: 1259\n",
            "Accuracy: 87.41\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.argmax(model5.predict(x_test, batch_size=128), axis=1)\n",
        "\n",
        "correct = np.sum(y_pred == y_test)\n",
        "total = len(y_test)\n",
        "\n",
        "print('Correct Predictions:', correct)\n",
        "print('Wrong Predictions:', total - correct)\n",
        "print('Accuracy:', correct / total * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3hKPlWWAACW"
      },
      "source": [
        "# Load Saved Model\n",
        "\n",
        "Load saved model and use it to predict a movie review statement's sentiment (positive or negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "NLksw_OaAA6v"
      },
      "outputs": [],
      "source": [
        "loaded_model = load_model('LSTM2_2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Ptv0FrxOAFJk"
      },
      "outputs": [],
      "source": [
        "review =\"Captivating performances and a gripping storyline make 'The Silence of the Lambs' a timeless classic. With masterful direction and intense suspense, it's a must-watch thriller that keeps you on the edge.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjgSG-lRAKjR",
        "outputId": "5284605d-0869-4699-a5d4-0231a78d31b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned:  Captivating performances and a gripping storyline make The Silence of the Lambs a timeless classic With masterful direction and intense suspense its a mustwatch thriller that keeps you on the edge\n",
            "Filtered:  ['captivating performances gripping storyline make the silence lambs timeless classic with masterful direction intense suspense mustwatch thriller keeps edge']\n"
          ]
        }
      ],
      "source": [
        "# Pre-process input\n",
        "regex = re.compile(r'[^a-zA-Z\\s]')\n",
        "review = regex.sub('', review)\n",
        "print('Cleaned: ', review)\n",
        "\n",
        "words = review.split(' ')\n",
        "filtered = [w for w in words if w not in english_stops]\n",
        "filtered = ' '.join(filtered)\n",
        "filtered = [filtered.lower()]\n",
        "\n",
        "print('Filtered: ', filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df_CwdpVANDW",
        "outputId": "f327ce24-57f0-4e7e-ad2b-a8a93cc22717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3857  275 3012  682   25    2 2982 8028 3653  270  411 4260  367 1448\n",
            "   674  605  855 1182    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]]\n"
          ]
        }
      ],
      "source": [
        "tokenize_words = token.texts_to_sequences(filtered)\n",
        "tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
        "print(tokenize_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9yu9OndARUt",
        "outputId": "20c305f7-2daf-4805-f4e4-abe1e9d69f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "[[1.]]\n"
          ]
        }
      ],
      "source": [
        "result = loaded_model.predict(tokenize_words)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "P0y-dN7PASQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c600f3-aa87-4f18-d827-c1b5adae0122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ],
      "source": [
        "if result >= 0.7:\n",
        "    print('positive')\n",
        "else:\n",
        "    print('negative')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}